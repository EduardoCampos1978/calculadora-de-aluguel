{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine-learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mario-RJunior/calculadora-imoveis/blob/master/machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpOq4u--M7R2"
      },
      "source": [
        "# Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8xvoezyNHcE"
      },
      "source": [
        "Agora é a etapa em que iremos gerar um modelo usando técnicas de Machine Learning para gerar um modelo que irá nos ajudar a prever o valor de aluguéis de imóveis da cidade de São Paulo. Para isso usaremos como base os arquivos csv gerados durante a [análise exploratória](https://github.com/Mario-RJunior/calculadora-imoveis/blob/master/analise_exploratoria.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wUzdqBant0D"
      },
      "source": [
        "## 1) Importar os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0mXOu7GDqI7"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgYFC3Kwn49T"
      },
      "source": [
        "treino = pd.read_csv('https://raw.githubusercontent.com/Mario-RJunior/calculadora-imoveis/master/treino_preprocessado.csv')\n",
        "teste = pd.read_csv('https://raw.githubusercontent.com/Mario-RJunior/calculadora-imoveis/master/teste_preprocessado.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQEdE4emoKTS"
      },
      "source": [
        "# Divisão para variáveis X e y\n",
        "X_train = treino.drop(labels='preco', axis=1)\n",
        "y_train = treino['preco']\n",
        "X_test = teste.drop('preco', axis=1)\n",
        "y_test = teste['preco']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X-gkUmytwzE"
      },
      "source": [
        "## 2) Modelo Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRtVrP_zt8db"
      },
      "source": [
        "Inicialmente criaremos um modelo denominado de ***Baseline*** que servirá como parâmetro para comparar seu resultado com os dos outros modelos que iremos gerar. É importante ressaltar que para que um modelo seja considerado bom ele deve ser superior ao baseline.\n",
        "\n",
        "Como modelo baseline usaremos um algorítmo de regressão linear."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKKZKHtst71t",
        "outputId": "baee632b-b672-4670-8e01-8335c52ba32e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Criando o modelo de regressão linear\n",
        "rl = LinearRegression()\n",
        "rl.fit(X_train, y_train)\n",
        "rl.score(X_test, y_test)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5617659641427768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj4GGgvyvRX-"
      },
      "source": [
        "Note que este modelo tem um score de aproximadamente 0.45, que é bem ruim. Agora, precisamos testar outros modelos para encontrar o melhor e mais adequado possível."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0JiI7ecbunJ"
      },
      "source": [
        "## 3) Testando outros modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP4zjyDjb58_"
      },
      "source": [
        "### 3.1) K-Nearest Neighbors (KNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb3WsYYCb0vP",
        "outputId": "0428d564-6c9e-4d19-bf24-fa4e628b4d9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "neigh = KNeighborsRegressor()\n",
        "neigh.fit(X_train, y_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                    weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYr2RCubcdvX",
        "outputId": "b9cb320c-495f-48c6-ed26-713865d9d785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "neigh.score(X_test, y_test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6399890193124183"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKWkllOWdWSQ"
      },
      "source": [
        "### 3.2) Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AKWTw5ydA-i",
        "outputId": "f828acdf-c937-4b85-dd36-b3956ffb7a6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "rf = RandomForestRegressor()\n",
        "rf.fit(X_train, y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
              "                      random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j65FN2FcddLW",
        "outputId": "8ccbbd0c-2b96-4b89-e2a9-fc57be18faa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "rf.score(X_test, y_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6419024223837924"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0P1e61ldzip"
      },
      "source": [
        "### 3.3) Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evGPW7RQdjgP",
        "outputId": "b608fa9f-bb91-49fa-a0ad-af6a4728d488",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "regr = AdaBoostRegressor()\n",
        "regr.fit(X_train, y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
              "                  n_estimators=50, random_state=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8lc3mP-dx7E",
        "outputId": "e1c1b442-6df0-452f-e16b-263e8a66a194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "regr.score(X_test, y_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6011958998622478"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qu1DPkycENV"
      },
      "source": [
        "Podemos agora, afim de otimizar nosso tempo criar um modelo para diversos algorítmos simultaneamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsNJEkNmcTd5"
      },
      "source": [
        "# Importando os estimadores\n",
        "from sklearn.linear_model import RidgeCV, Lasso, ElasticNet, LassoLars, HuberRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noOe3Q-scuhw"
      },
      "source": [
        "# Criando uma lista com todos os estimadores\n",
        "reg_list = [RidgeCV(),\n",
        "            LGBMRegressor(), \n",
        "            XGBRegressor(objective='reg:squarederror'),\n",
        "            SVR(),\n",
        "            GradientBoostingRegressor(),\n",
        "            MLPRegressor()\n",
        "            ]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U8fLkfjc9c3",
        "outputId": "87cc0eec-2c2a-47e5-c95f-26873d3133cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "# Criando o modelo\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "for reg in reg_list:\n",
        "    print(f'Treinando Modelo {reg.__class__.__name__}')\n",
        "    reg.fit(X_train, y_train)\n",
        "    \n",
        "    train_score = reg.score(X_train, y_train)\n",
        "    cv_scores = cross_val_score(reg, X_train, y_train)\n",
        "    test_score = reg.score(X_test, y_test)\n",
        "    \n",
        "    print(f\"R2 Score Train: {train_score}\")\n",
        "    print(f\"R2 Score Valid: {np.mean(cv_scores):.2f} +- {np.std(cv_scores):.2f}\")\n",
        "    print(f\"R2 Score Test: {test_score}\")\n",
        "    print('='*80)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Treinando Modelo RidgeCV\n",
            "R2 Score Train: 0.694995494792588\n",
            "R2 Score Valid: 0.69 +- 0.04\n",
            "R2 Score Test: 0.5628158188285721\n",
            "================================================================================\n",
            "Treinando Modelo LGBMRegressor\n",
            "R2 Score Train: 0.8335649897226411\n",
            "R2 Score Valid: 0.73 +- 0.01\n",
            "R2 Score Test: 0.6524018217807195\n",
            "================================================================================\n",
            "Treinando Modelo XGBRegressor\n",
            "R2 Score Train: 0.8173085197618972\n",
            "R2 Score Valid: 0.74 +- 0.01\n",
            "R2 Score Test: 0.6748886425763778\n",
            "================================================================================\n",
            "Treinando Modelo SVR\n",
            "R2 Score Train: 0.7331335431720392\n",
            "R2 Score Valid: 0.72 +- 0.03\n",
            "R2 Score Test: 0.6424482920301618\n",
            "================================================================================\n",
            "Treinando Modelo GradientBoostingRegressor\n",
            "R2 Score Train: 0.8279163984754841\n",
            "R2 Score Valid: 0.74 +- 0.01\n",
            "R2 Score Test: 0.663573061815669\n",
            "================================================================================\n",
            "Treinando Modelo MLPRegressor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "R2 Score Train: 0.7150139858715128\n",
            "R2 Score Valid: 0.70 +- 0.05\n",
            "R2 Score Test: 0.5895900503274301\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}